Project: Fun With Banking

Full Name: Yuan Li

--------------
How to Run it:
-------------- 

# Step 1: Comfigure ODBC
When using Mac OS X, the installer will create a sample user DSN in odbc.ini in either of the following locations:
```
~/Library/ODBC/odbc.ini
~/.odbc.ini
```

You may configure your `.odbc.ini` file by using the following:
```
[ODBC Data Sources]
my_driver = postodbc

[ODBC]
Trace = 0

[my_driver]
Driver      = /usr/local/lib/psqlodbcw.so
ServerName  = localhost
Port        = 5432
Database    = banking_db
Username    = postgres
Password    = 12345
```

And configure your `odbcinst.ini` file by using the following:
```
[ODBC Drivers]
postodbc = Installed

[postodbc]
Description     = PostgreSQL ODBC driver
Driver          = /usr/local/lib/psqlodbcw.so
Setup           = /usr/local/lib/psqlodbcw.so
Debug           = 0
```

---
# Step 2: Set up local environment
Cd to your project directly, and create a virtual environment by using the following command:
```
$ virtualenv venv
```
and activate the virtual environment that you created:
```
$. ./venv/bin/activate
```
then you may install all dependencies using the following:
```
$ pip install -r requirements.txt
```

---
# Step 3: Prepare Docker environment
First, pull postgres image from Docker hub by using
```
$ docker pull postgres:9.6
```
I use postgres version 9.6 here, but you may choose other versions. Depending on your needs, you may pull other images from Docker hub, for example, other images I pulled include python, busybox, etc.


---
# Step 4: Build and run Docker image 
In order to do that, you may simply run the setup.sh:
```
$ . ./setup.sh
```

---
# Step 5: Connect to Postgres in Docker and populate test data
In project folder, you may run the test.py file by using:

```
$ python test.py
```
This process include three tasks:
- connect to ​Postgres running in the docker via pyodbc​​
- populate banking_db with mock test data generated by Faker and Random
- run demonstration SQL queries

---
# Step 6: Check database 

After the database is successfully built, you may use the following command to enter the Docker container:
```
$ docker exec -it custom_psql_running /bin/sh
```

Then you may enter the database by using the following command:
```
psql -h localhost -U postgres -d postgres
```

Till this step, you should be able to connect to the database that we created by using:
```
postgres=# \c banking_db;
```
Also take a look at the tables that we created earlier:
```
banking_db=# \dt;
```
You should be able to see all three tables listed, including customer, account, customer_account.

Then you may play around with the database with SQL queries, for example:
```
select * from customer limit 5;
```
This will give you the top 5 customer records in the database.
Have fun!


----------
Questions
----------
● How much time did you spend on this?

A: I spent roughly 8 hours to finish the tasks. Including some learning time for me to get more familiar with Docker and Faker.


● Did you receive outside help (eg a friend, colleague, forum posting, etc)?

A: Yes, I got help from a number of posts from stack overflows as well as from people's blogs, which I find very helpful.


● What were the most useful web pages (URLs) in completing this project?

A: There are several web pages that I found very useful, including:
- Docker curriculum - https://docker-curriculum.com/
- Docker Docs, Get Started, Part 1: Orientation and setup - https://docs.docker.com/get-started/
- Faker Documentation - https://faker.readthedocs.io/en/master/


● What new technologies did you have to learn to complete this?

A: I learn a lot about Docker and virtual machines, and also how to use Faker and random to generate test data. 


● Do you believe your results are correct? Why?

A: I believe my results are correct because I checked at each step to make sure the output was expected. First, I checked the database schema and made sure it functions properly in the Docker container. The test data could also be smoothly populated to the database, and my SQL queries were able to get results as what I would expect. However, there are indeed some part of uncertainty that I will elaborate on the next question.


● What are the biggest gaps between what you delivered and the requirements?

A: One of the uncertainty lies in the test data that I generated using Faker and Random. Some of the test data indeed is not consistent enough in certain ways. For example, the city generated may not necessarily match the state in reality in the customer table. Also, it might be more nuance to consider the relationship between customer created date and account created date, since it would make less sense if account created would be earlier than customer created date. These consideration will be extremely helpful to generate realistic test data; however, due to limitation of time, I did not delve too deep into these considerations for this project.

Another uncertainty lies in the understanding of the last SQL query required. From my understanding, each of the top 10 customers' largest bank account should transfer 10% to each one of the bottom 10 customer's smallest account, so I simply use a cross join to fulfill this relationship. 